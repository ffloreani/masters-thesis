{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, Input, Model, regularizers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    \n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "original_dim = 5000 * 1\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim_0 = 1536\n",
    "intermediate_dim_1 = 1024\n",
    "intermediate_dim_2 = 512\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 100\n",
    "\n",
    "REGULAR = \"reg\"\n",
    "CHIMERIC = \"chi\"\n",
    "REPEAT = \"rep\"\n",
    "LOW_QUALITY = \"loq\"\n",
    "\n",
    "INPUT_LENGTH = 5000\n",
    "INPUT_THRESHOLD = 1000\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "\n",
    "def create_datasets(tsv_input):\n",
    "    data = pd.read_csv(tsv_input, delimiter=\"\\t\")\n",
    "\n",
    "    # Filter out all low quality reads\n",
    "    data = data.loc[data.CAT != LOW_QUALITY]\n",
    "\n",
    "    # Convert sequence string to float array\n",
    "    data.PTS = data.PTS.apply(string_to_array)\n",
    "\n",
    "    # Convert labels from strings to ints\n",
    "    ys = data.CAT.apply(category_to_int).to_numpy()\n",
    "    xs = np.stack(data.PTS.array)\n",
    "\n",
    "    encoded_ys = to_categorical(ys, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(\"XS shape: {}\".format(xs.shape))\n",
    "    print(\"One-hot encoded YS shape: {}\".format(encoded_ys.shape))\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(xs, encoded_ys, test_size=0.3)\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def create_unlabeled_datasets(tsv_input):\n",
    "    data = pd.read_csv(tsv_input, delimiter=\"\\t\")\n",
    "\n",
    "    # Filter out all low quality reads\n",
    "    data = data.loc[data.CAT != LOW_QUALITY]\n",
    "\n",
    "    # Convert sequence string to float array\n",
    "    data.PTS = data.PTS.apply(string_to_array)\n",
    "    xs = np.stack(data.PTS.array)\n",
    "    print(\"Unlabeled XS shape: {}\".format(xs.shape))\n",
    "\n",
    "    train_x, test_x = train_test_split(xs, test_size=0.3)\n",
    "\n",
    "    return train_x, test_x\n",
    "\n",
    "\n",
    "def string_to_array(data):\n",
    "    data_string = str(data)\n",
    "    split = data_string.split(',')\n",
    "\n",
    "    return np.array([float(i) for i in split])\n",
    "\n",
    "\n",
    "def category_to_int(data):\n",
    "    category = str(data)\n",
    "    if category == REGULAR:\n",
    "        return 0\n",
    "    elif category == REPEAT:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim_0, activation='relu', activity_regularizer=regularizers.l1(10e-4))(inputs)\n",
    "x = Dense(intermediate_dim_1, activation='relu')(x)\n",
    "x = Dense(intermediate_dim_2, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reparameterization trick to push the sampling out as input\n",
    "z = Lambda(sampling, name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 5000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1536)         7681536     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1573888     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,782,276\n",
      "Trainable params: 9,782,276\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "plot_model(encoder, to_file='vae_mlp_svm_encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim_2, activation='relu')(latent_inputs)\n",
    "x = Dense(intermediate_dim_1, activation='relu')(x)\n",
    "x = Dense(intermediate_dim_0, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1536)              1574400   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5000)              7685000   \n",
      "=================================================================\n",
      "Total params: 9,786,248\n",
      "Trainable params: 9,786,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "plot_model(decoder, to_file='vae_mlp_svm_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = mse(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"decoder\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"decoder\".\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 9782276   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 5000)              9786248   \n",
      "=================================================================\n",
      "Total params: 19,568,524\n",
      "Trainable params: 19,568,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adagrad')\n",
    "vae.summary()\n",
    "\n",
    "plot_model(vae, to_file='vae_mlp_svm.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model):\n",
    "    loss = model.history['loss']\n",
    "    val_loss = model.history['val_loss']\n",
    "    plt.figure()\n",
    "    plt.plot(loss, 'r-', label='Training loss')\n",
    "    plt.plot(val_loss, 'b-', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_decoded(decoded_x, n):\n",
    "    idxs = range(INPUT_LENGTH)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n, ncols=n, figsize=(15,10))\n",
    "    fig.patch.set_visible(False)\n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "        for j, col in enumerate(row):\n",
    "            col.axis('off')\n",
    "            col.plot(idxs, decoded_x[i * n + j].tolist())\n",
    "    plt.savefig('grid_generated_vae_svm.png', facecolor='w')\n",
    "    print(\"*****   Manifold generation complete   *****\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(matrix):\n",
    "    df_cm = pd.DataFrame(matrix, [\"regular\", \"repeat\", \"chimeric\"], [\"regular\", \"repeat\", \"chimeric\"])\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sb.heatmap(df_cm, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled XS shape: (7460, 5000)\n",
      "Train on 5222 samples, validate on 2238 samples\n",
      "Epoch 1/100\n",
      "5222/5222 [==============================] - 3s 583us/step - loss: 155.2512 - val_loss: 30.4355\n",
      "Epoch 2/100\n",
      "5222/5222 [==============================] - 2s 389us/step - loss: 26.9300 - val_loss: 28.4834\n",
      "Epoch 3/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 30.2412 - val_loss: 23.5203\n",
      "Epoch 4/100\n",
      "5222/5222 [==============================] - 3s 504us/step - loss: 19.7506 - val_loss: 20.2294\n",
      "Epoch 5/100\n",
      "5222/5222 [==============================] - 2s 386us/step - loss: 18.4231 - val_loss: 20.0114\n",
      "Epoch 6/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 18.9110 - val_loss: 25.5040\n",
      "Epoch 7/100\n",
      "5222/5222 [==============================] - 2s 391us/step - loss: 18.1562 - val_loss: 19.3798\n",
      "Epoch 8/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 17.8021 - val_loss: 19.3881\n",
      "Epoch 9/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 17.5729 - val_loss: 18.9266\n",
      "Epoch 10/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 17.4675 - val_loss: 22.7353\n",
      "Epoch 11/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 17.0424 - val_loss: 19.2345\n",
      "Epoch 12/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 17.1477 - val_loss: 17.5758\n",
      "Epoch 13/100\n",
      "5222/5222 [==============================] - 2s 388us/step - loss: 16.2843 - val_loss: 17.4037\n",
      "Epoch 14/100\n",
      "5222/5222 [==============================] - 1s 260us/step - loss: 16.8960 - val_loss: 17.7070\n",
      "Epoch 15/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 16.5731 - val_loss: 17.7411\n",
      "Epoch 16/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 15.7008 - val_loss: 16.6914\n",
      "Epoch 17/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 15.4798 - val_loss: 17.2087\n",
      "Epoch 18/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 15.6911 - val_loss: 17.0577\n",
      "Epoch 19/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 15.3197 - val_loss: 20.7791\n",
      "Epoch 20/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 15.5256 - val_loss: 16.9940\n",
      "Epoch 21/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 14.8761 - val_loss: 15.8085\n",
      "Epoch 22/100\n",
      "5222/5222 [==============================] - 2s 392us/step - loss: 14.9750 - val_loss: 15.6117\n",
      "Epoch 23/100\n",
      "5222/5222 [==============================] - 2s 390us/step - loss: 15.0821 - val_loss: 15.5078\n",
      "Epoch 24/100\n",
      "5222/5222 [==============================] - 2s 394us/step - loss: 14.3500 - val_loss: 15.2311\n",
      "Epoch 25/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 15.1473 - val_loss: 15.2409\n",
      "Epoch 26/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 14.1785 - val_loss: 16.0258\n",
      "Epoch 27/100\n",
      "5222/5222 [==============================] - 2s 390us/step - loss: 14.2907 - val_loss: 14.7967\n",
      "Epoch 28/100\n",
      "5222/5222 [==============================] - 1s 268us/step - loss: 14.4930 - val_loss: 16.5078\n",
      "Epoch 29/100\n",
      "5222/5222 [==============================] - 2s 393us/step - loss: 13.5894 - val_loss: 14.2725\n",
      "Epoch 30/100\n",
      "5222/5222 [==============================] - 2s 394us/step - loss: 13.1754 - val_loss: 14.1972\n",
      "Epoch 31/100\n",
      "5222/5222 [==============================] - 1s 265us/step - loss: 13.3976 - val_loss: 15.1394\n",
      "Epoch 32/100\n",
      "5222/5222 [==============================] - 2s 389us/step - loss: 13.8326 - val_loss: 14.1808\n",
      "Epoch 33/100\n",
      "5222/5222 [==============================] - 1s 265us/step - loss: 13.2132 - val_loss: 16.1122\n",
      "Epoch 34/100\n",
      "5222/5222 [==============================] - 2s 388us/step - loss: 12.9700 - val_loss: 13.9069\n",
      "Epoch 35/100\n",
      "5222/5222 [==============================] - 2s 390us/step - loss: 13.4243 - val_loss: 13.8312\n",
      "Epoch 36/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 13.5222 - val_loss: 14.9439\n",
      "Epoch 37/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.7196 - val_loss: 13.8784\n",
      "Epoch 38/100\n",
      "5222/5222 [==============================] - 1s 267us/step - loss: 13.3877 - val_loss: 13.8375\n",
      "Epoch 39/100\n",
      "5222/5222 [==============================] - 2s 379us/step - loss: 12.9088 - val_loss: 13.6845\n",
      "Epoch 40/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.6097 - val_loss: 13.8614\n",
      "Epoch 41/100\n",
      "5222/5222 [==============================] - 2s 388us/step - loss: 13.1315 - val_loss: 13.5251\n",
      "Epoch 42/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 13.1893 - val_loss: 15.4464\n",
      "Epoch 43/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 13.1384 - val_loss: 13.5562\n",
      "Epoch 44/100\n",
      "5222/5222 [==============================] - 2s 385us/step - loss: 12.4943 - val_loss: 13.4520\n",
      "Epoch 45/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.4890 - val_loss: 13.8456\n",
      "Epoch 46/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 13.1914 - val_loss: 13.4914\n",
      "Epoch 47/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 12.6626 - val_loss: 13.3895\n",
      "Epoch 48/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.8741 - val_loss: 13.9472\n",
      "Epoch 49/100\n",
      "5222/5222 [==============================] - 1s 265us/step - loss: 12.3450 - val_loss: 13.8071\n",
      "Epoch 50/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 13.0236 - val_loss: 13.4720\n",
      "Epoch 51/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.2276 - val_loss: 13.7015\n",
      "Epoch 52/100\n",
      "5222/5222 [==============================] - 2s 386us/step - loss: 12.3214 - val_loss: 13.1901\n",
      "Epoch 53/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 13.0024 - val_loss: 13.3938\n",
      "Epoch 54/100\n",
      "5222/5222 [==============================] - 1s 265us/step - loss: 12.5127 - val_loss: 13.2468\n",
      "Epoch 55/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.5949 - val_loss: 14.0908\n",
      "Epoch 56/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 13.5389 - val_loss: 13.3711\n",
      "Epoch 57/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 12.2701 - val_loss: 13.2565\n",
      "Epoch 58/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 12.2348 - val_loss: 13.1022\n",
      "Epoch 59/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 12.8448 - val_loss: 18.3376\n",
      "Epoch 60/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.3521 - val_loss: 13.2342\n",
      "Epoch 61/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 12.4412 - val_loss: 13.4109\n",
      "Epoch 62/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.1201 - val_loss: 13.1808\n",
      "Epoch 63/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.5679 - val_loss: 13.5212\n",
      "Epoch 64/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.2292 - val_loss: 13.3042\n",
      "Epoch 65/100\n",
      "5222/5222 [==============================] - 1s 260us/step - loss: 12.5950 - val_loss: 13.6336\n",
      "Epoch 66/100\n",
      "5222/5222 [==============================] - 2s 389us/step - loss: 12.1151 - val_loss: 13.0572\n",
      "Epoch 67/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.7069 - val_loss: 13.5751\n",
      "Epoch 68/100\n",
      "5222/5222 [==============================] - 2s 386us/step - loss: 12.2469 - val_loss: 13.0031\n",
      "Epoch 69/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 12.4183 - val_loss: 13.1734\n",
      "Epoch 70/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.3030 - val_loss: 13.4324\n",
      "Epoch 71/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.3588 - val_loss: 13.8931\n",
      "Epoch 72/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 13.2702 - val_loss: 13.1685\n",
      "Epoch 73/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 12.0366 - val_loss: 13.1504\n",
      "Epoch 74/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 12.1747 - val_loss: 12.9280\n",
      "Epoch 75/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 11.9034 - val_loss: 12.9387\n",
      "Epoch 76/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 12.0839 - val_loss: 13.6392\n",
      "Epoch 77/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 12.1639 - val_loss: 12.9517\n",
      "Epoch 78/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.8120 - val_loss: 12.9702\n",
      "Epoch 79/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 11.9801 - val_loss: 13.0538\n",
      "Epoch 80/100\n",
      "5222/5222 [==============================] - 1s 264us/step - loss: 11.8849 - val_loss: 12.9618\n",
      "Epoch 81/100\n",
      "5222/5222 [==============================] - 2s 391us/step - loss: 12.7453 - val_loss: 12.9193\n",
      "Epoch 82/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.0939 - val_loss: 18.8488\n",
      "Epoch 83/100\n",
      "5222/5222 [==============================] - 2s 389us/step - loss: 12.2398 - val_loss: 12.8768\n",
      "Epoch 84/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 12.3092 - val_loss: 12.8621\n",
      "Epoch 85/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.0217 - val_loss: 17.5192\n",
      "Epoch 86/100\n",
      "5222/5222 [==============================] - 1s 263us/step - loss: 12.2248 - val_loss: 12.8877\n",
      "Epoch 87/100\n",
      "5222/5222 [==============================] - 2s 386us/step - loss: 12.0908 - val_loss: 12.8487\n",
      "Epoch 88/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.2231 - val_loss: 12.9582\n",
      "Epoch 89/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.0940 - val_loss: 12.8558\n",
      "Epoch 90/100\n",
      "5222/5222 [==============================] - 1s 260us/step - loss: 12.3720 - val_loss: 15.9350\n",
      "Epoch 91/100\n",
      "5222/5222 [==============================] - 1s 260us/step - loss: 12.1443 - val_loss: 13.0544\n",
      "Epoch 92/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 12.0464 - val_loss: 13.1828\n",
      "Epoch 93/100\n",
      "5222/5222 [==============================] - 2s 387us/step - loss: 11.8576 - val_loss: 12.8465\n",
      "Epoch 94/100\n",
      "5222/5222 [==============================] - 1s 260us/step - loss: 11.9675 - val_loss: 21.5364\n",
      "Epoch 95/100\n",
      "5222/5222 [==============================] - 1s 259us/step - loss: 13.1285 - val_loss: 13.0364\n",
      "Epoch 96/100\n",
      "5222/5222 [==============================] - 1s 262us/step - loss: 11.8761 - val_loss: 12.9428\n",
      "Epoch 97/100\n",
      "5222/5222 [==============================] - 2s 385us/step - loss: 11.8265 - val_loss: 12.8424\n",
      "Epoch 98/100\n",
      "5222/5222 [==============================] - 1s 261us/step - loss: 12.4211 - val_loss: 12.8639\n",
      "Epoch 99/100\n",
      "5222/5222 [==============================] - 2s 389us/step - loss: 11.7826 - val_loss: 12.7829\n",
      "Epoch 100/100\n",
      "5222/5222 [==============================] - 1s 265us/step - loss: 12.0295 - val_loss: 12.8372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "cp = ModelCheckpoint(filepath=\"vae_mlp_svm_unlabeled.h5\", save_best_only=True, verbose=0)\n",
    "\n",
    "vae_train_x, vae_test_x = create_unlabeled_datasets(\"/floyd/input/overlaps/classified_7000.tsv\")\n",
    "\n",
    "vae_train_x = vae_train_x / np.max(vae_train_x)\n",
    "vae_test_x = vae_test_x / np.max(vae_test_x)\n",
    "\n",
    "history = vae.fit(vae_train_x, epochs=epochs, batch_size=batch_size, validation_data=(vae_test_x, None), callbacks=[es, cp])\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f493f788921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train SVM classifier on training labels \\& training latent samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/floyd/input/overlaps/categorized_400.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_train_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_train_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf_test_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_test_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Train SVM classifier on training labels \\& training latent samples\n",
    "clf_train_x, clf_train_y, clf_test_x, clf_test_y = create_datasets(\"/floyd/input/overlaps/categorized_400.tsv\")\n",
    "clf_train_x = clf_train_x / np.max(clf_train_x)\n",
    "clf_test_x = clf_test_x / np.max(clf_test_x)\n",
    "\n",
    "clf_train_z, _, _ = encoder.predict(clf_train_x, batch_size=batch_size)\n",
    "print(\"Training Z shape: {}\".format(clf_train_z.shape))\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(clf_train_z, clf_train_y.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 5000)\n",
      "*****   Manifold generation complete   *****\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2051\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2053\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2263\u001b[0m         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox_extra_artists\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m             \u001b[0martists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m             \u001b[0martists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox_extra_artists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_default_bbox_extra_artists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                 \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m         \u001b[0;31m# we don't want the figure's patch to influence the bbox calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         \u001b[0mbbox_artists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 900 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 30  # how many overlaps we will display\n",
    "u_grid = np.dstack(np.meshgrid(np.linspace(0.01, 0.99, n), np.linspace(0.01, 0.99, n)))\n",
    "z_grid = norm.ppf(u_grid)\n",
    " \n",
    "recons_x = decoder.predict(z_grid.reshape(n * n, 2))\n",
    "print(recons_x.shape)\n",
    "\n",
    "plot_decoded(recons_x, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-af4db682b956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_test_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_test_z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_test_z\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Test classifier\n",
    "clf_test_z, _, _ = encoder.predict(clf_test_x, batch_size=batch_size)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(clf_test_z[:, 0], clf_test_z[:, 1], c=clf_test_y)\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pred_y = svm.predict(clf_test_z)\n",
    "print(pred_y)\n",
    "\n",
    "matrix = metrics.confusion_matrix(clf_test_y.argmax(axis=1), pred_y)\n",
    "plot_confusion_matrix(matrix)\n",
    "\n",
    "print(metrics.classification_report(clf_test_y.argmax(axis=1), pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
